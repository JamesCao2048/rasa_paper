% !TeX root = ../main.tex

\section{Related Work}
\vspace{-3pt}

\textbf{Study of ML-Enabled Systems}. While much of the attention has been on ML models, less attention has been paid on system-level analysis~\cite{Christian2022}. Peng et al.~\cite{pengFirstLookIntegration2020} investigated~the~integration of ML models in Apollo by analyzing how ML models~interact with the system and how is the current testing effort. Besides, Nahar et al.~\cite{Nahar2022} explored collaboration challenges between data scientists and software engineers through interviews.~Amershi et al.~\cite{Amershi2019} and Bernardi et al.~\cite{Bernardi2019} reported~challenges and~practices of MLOps (from model requirement~to~model~monitoring) at Microsoft and Booking.com. Although they~still~take~a~model-centric view,~they~emphasize~that~models can~be~complexly~entangled to cause non-monotonic~errors~\cite{Amershi2019} and model quality~improvement does not necessarily indicate system value~gain~\cite{Bernardi2019}. Further, Yokoyama~\cite{Yokoyama2019} developed an architectural pattern to separate ML and non-ML components, while Serban~and~Visser \cite{Serban2022} surveyed architectural challenges for ML-enabled systems. Sculley et al.~\cite{hidden_technical_debt} identified ML-specific technical debt~in~ML-enabled systems, while Tang et al.~\cite{tang2021empirical} further derived new~ones from real-world code refactorings. In addition, some attempts were made on the problem of ML component entanglement~\cite{Amershi2019}, e.g., performing metamorphic testing on a system with two~ML components~\cite{Zhang2016}, troubleshooting failures in a system with~three ML components by human intellect~\cite{nushi2017human}, and decomposing~errors in a system with two or three ML components~\cite{fix_that_fails}. These studies explore the interaction among models but only~on~simple systems. Moreover, Abdessalem et al.~\cite{Abdessalem2018, Abdessalem2020} studied the feature interaction failures in self-driving systems, and proposed testing and repairing approaches to automatically detect and fix them. Apel et al.~\cite{feature_interaction} also discussed feature interactions in ML-enabled systems, and suggested strategies to cope with them.

The main difference from the previous work is that we~take~a large-scale complex ML-enabled system, explore its complexity at three levels, and analyze the impact of its complexity~on~testing. The closest work is Peng et al.'s~\cite{pengFirstLookIntegration2020}, but we report~a~deeper complexity analysis and also conduct a testing impact analysis.

\textbf{Mutation Testing for DL Models}. Jia et al.~\cite{JiaMutation}~used~syntactic mutators for traditional programs to DL models.~DeepMutation \cite{DeepMutation} and DeepMutation++~\cite{DeepMutation++} defined DL-specific mutators. DeepCrime~\cite{DeepCrime} derived DL-specific  mutators based~on real~DL bugs. 
Jahangirova and Tonella~\cite{mutation_evaluation} evaluated syntactic and DL-specific mutators. These studies are focused on model-level mutation, while we target at system-level mutation.

\textbf{Testing for Dialogue Systems}. Bozic and Wotawa~\cite{Bozic2018}~proposed a security testing approach for chatbots to prevent cross-site scripting and SQL injection. Bozic et al.~\cite{Bozic2019a}~tested a hotel booking chatbot via planning. Bozic and Wotawa~\cite{Bozic2019b}~introduced a metamorphic testing approach for chatbots. Similarly, Liu et al.~\cite{liu2021dialtest} used semantic metamorphic relations to test the NLU module in dialogue systems. Despite the effort,~less~attention has been paid on system-level testing of dialogue systems.

